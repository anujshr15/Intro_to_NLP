{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes accuracy:  83.43373493975903\n",
      "MultiNB Naive Bayes accuracy:  71.6867469879518\n",
      "BernNB Naive Bayes accuracy:  72.59036144578313\n",
      "SGD accuracy:  69.87951807228916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj\\Miniconda3\\envs\\condaenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy:  71.83734939759037\n",
      "Linear_SVC accuracy:  69.87951807228916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj\\Miniconda3\\envs\\condaenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC accuracy:  68.97590361445783\n",
      "voted_classifier accuracy:  73.3433734939759\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.svm import SVC,NuSVC,LinearSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VotedClassifier(ClassifierI):\n",
    "    def __init__(self,*classifiers):\n",
    "        self._classifers=classifiers\n",
    "\n",
    "    def classify(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf= choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# documents=[]\n",
    "# for category in movie_reviews.categories():\n",
    "#     for fileid in movie_reviews.fileids(category):\n",
    "#         documents.append((list(movie_reviews.words(fileid)),category))\n",
    "#\n",
    "# random.shuffle(documents)\n",
    "#\n",
    "# all_words=[]\n",
    "# for w in movie_reviews.words():\n",
    "#     all_words.append(w.lower())\n",
    "\n",
    "\n",
    "\n",
    "documents_f=open(\"documents.pickle\",\"rb\")\n",
    "documents=pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "words_features_f=open(\"word_features5k\",\"rb\")\n",
    "word_features=pickle.load(words_features_f)\n",
    "words_features_f.close()\n",
    "\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words=word_tokenize(document)\n",
    "    features={}\n",
    "    for w in word_features:\n",
    "        features[w]=( w in words )\n",
    "\n",
    "    return features\n",
    "\n",
    "#print(find_features(movie_reviews.words('neg/cv000_29416.txt')))\n",
    "\n",
    "\n",
    "\n",
    "featuresets_f=open(\"featuresets.pickle\",\"rb\")\n",
    "featuresets=pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "\n",
    "training_set= featuresets[:10000]\n",
    "testing_set= featuresets[10000:]\n",
    "\n",
    "# classifier=nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "\n",
    "classifier_f= open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "\n",
    "print(\"Original Naive Bayes accuracy: \",nltk.classify.accuracy(classifier,testing_set)*100)\n",
    "#classifier.show_most_informative_features(15)\n",
    "\n",
    "\n",
    "# save_classifier=open(\"naivebayes.pickle\",\"wb\")\n",
    "# pickle.dump(classifier,save_classifier)\n",
    "# save_classifier.close()\n",
    "\n",
    "\n",
    "# GaussianNB,MultinomialNB,BernoulliNB\n",
    "#  SGDClassifier,LogisticRegression\n",
    "#  SVC,NuSVC\n",
    "\n",
    "# GNB_classifier=SklearnClassifier(GaussianNB())\n",
    "# GNB_classifier.train(training_set)\n",
    "# print(\"GNB Naive Bayes accuracy: \",nltk.classify.accuracy(GNB_classifier,testing_set)*100)\n",
    "\n",
    "# MultiNB_classifier=SklearnClassifier(MultinomialNB())\n",
    "\n",
    "\n",
    "\n",
    "classifier_f= open(\"MultiNB_classifier.pickle\",\"rb\")\n",
    "MultiNB_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "MultiNB_classifier.train(training_set)\n",
    "print(\"MultiNB Naive Bayes accuracy: \",nltk.classify.accuracy(MultiNB_classifier,testing_set)*100)\n",
    "\n",
    "\n",
    "\n",
    "# BernNB_classifier=SklearnClassifier(BernoulliNB())\n",
    "classifier_f= open(\"BernNB_classifer.pickle\",\"rb\")\n",
    "BernNB_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "BernNB_classifier.train(training_set)\n",
    "print(\"BernNB Naive Bayes accuracy: \",nltk.classify.accuracy(BernNB_classifier,testing_set)*100)\n",
    "\n",
    "# SGD_classifier=SklearnClassifier(SGDClassifier())\n",
    "classifier_f= open(\"SGD_classifer.pickle\",\"rb\")\n",
    "SGD_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "SGD_classifier.train(training_set)\n",
    "print(\"SGD accuracy: \",nltk.classify.accuracy(SGD_classifier,testing_set)*100)\n",
    "\n",
    "# LR_classifier=SklearnClassifier(LogisticRegression())\n",
    "classifier_f= open(\"LR_classifer.pickle\",\"rb\")\n",
    "LR_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "LR_classifier.train(training_set)\n",
    "print(\"LR accuracy: \",nltk.classify.accuracy(LR_classifier,testing_set)*100)\n",
    "\n",
    "# SVC_classifier=SklearnClassifier(SVC())\n",
    "# SVC_classifier.train(training_set)\n",
    "# print(\"SVC accuracy: \",nltk.classify.accuracy(SVC_classifier,testing_set)*100)\n",
    "\n",
    "# Linear_SVC_classifier=SklearnClassifier(LinearSVC())\n",
    "classifier_f= open(\"Linear_SVC_classifer.pickle\",\"rb\")\n",
    "Linear_SVC_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "Linear_SVC_classifier.train(training_set)\n",
    "print(\"Linear_SVC accuracy: \",nltk.classify.accuracy(Linear_SVC_classifier,testing_set)*100)\n",
    "\n",
    "# NuSVC_classifier=SklearnClassifier(NuSVC())\n",
    "classifier_f= open(\"NuSVC_classifer.pickle\",\"rb\")\n",
    "NuSVC_classifier=pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC accuracy: \",nltk.classify.accuracy(NuSVC_classifier,testing_set)*100)\n",
    "\n",
    "voted_classifier=VotedClassifier(classifier,MultiNB_classifier,Linear_SVC_classifier,BernNB_classifier,SGD_classifier,LR_classifier,NuSVC_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy: \",nltk.classify.accuracy(voted_classifier,testing_set)*100)\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment(\"Amazing work done by him! Such a class actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 0.5714285714285714)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment(\"Awesome work! he's a good actor and really outshadowed everyone\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This movie was awesome! The acting was great, plot was wonderful, and there were pythons...so yea!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
